{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "with open(\"embeddings.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "            \n",
    "    for row in reader:\n",
    "        if len(row) >= 2:  # Ensure row has both paragraph and embedding\n",
    "            paragraph = row[0]\n",
    "            # Convert embedding string back to list of floats\n",
    "            embedding_str = row[1]\n",
    "            embedding = [float(x) for x in embedding_str.split(',')]\n",
    "            embeddings.append([paragraph, embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1: Union[List[float], np.ndarray],\n",
    "                     v2: Union[List[float], np.ndarray]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "    Args:\n",
    "        v1: First vector (list or numpy array of floats)\n",
    "        v2: Second vector (list or numpy array of floats)\n",
    "    Returns:\n",
    "        float: Cosine similarity score between -1 and 1\n",
    "    Raises:\n",
    "        ValueError: If vectors are not of equal length or contain all zeros\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays if they aren't already\n",
    "    v1_array = np.array(v1)\n",
    "    v2_array = np.array(v2)\n",
    "    # Check if vectors are of equal length\n",
    "    if v1_array.shape != v2_array.shape:\n",
    "        raise ValueError(\"Vectors must be of equal length\")\n",
    "    # Calculate dot product and magnitudes\n",
    "    dot_product = np.dot(v1_array, v2_array)\n",
    "    magnitude1 = np.linalg.norm(v1_array)\n",
    "    magnitude2 = np.linalg.norm(v2_array)\n",
    "    # Check for zero vectors\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        raise ValueError(\"Vectors must not be zero vectors\")\n",
    "    # Calculate cosine similarity\n",
    "    similarity = dot_product / (magnitude1 * magnitude2)\n",
    "    # Due to floating point precision, we might get values slightly outside [-1, 1]\n",
    "    return max(min(similarity, 1.0), -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What happened in October at Amazon?\"\n",
    "input_body = {\n",
    "                \"inputText\": question\n",
    "            }\n",
    "response = bedrock.invoke_model(\n",
    "                modelId=\"amazon.titan-embed-text-v2:0\",\n",
    "                body=json.dumps(input_body)\n",
    "            )\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "query_embedding = response_body.get(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarites = [[embedding[0], float(cosine_similarity(query_embedding, embedding[1]))] for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"amazon Dear Shareholders: Last year at this time, I shared my enthusiasm and optimism for Amazon's future. Today, I have even more. The reasons are many, but start with the progress we've made in our financial results and customer\", 0.3304279986546396], [\"traffic, sales, and service levels: Amazon.com's employee base grew from 158 to 614, and we significantly strengthened our management team. Distribution center capacity grew from 50,000 to 285,000 square feet, including a 70% expansion of our Seattle facilities and the launch of our second distribution center in Delaware in November.\", 0.31344220407823314], ['Amazon grew SO quickly the first few years. This coupling was further highlighted by a heavyweight mechanism we used to operate called \"NPI.\" Any new initiative requiring work from multiple internal teams had to be reviewed by this NPI cabal where each team would communicate how many people-weeks their work would take. This bottleneck constrained what we accomplished, frustrated the heck out of us, and inspired us to eradicate it by refactoring these', 0.2990482054907726], [\"product and geographic expansion; and the need for large continuing investments to meet an expanding market opportunity. However, as we've long said, online bookselling, and online commerce in general, should prove to be a very large market, and it's likely that a number of companies will see significant benefit. We feel good about what we've done, and even more excited about what we want to do. 1997 was indeed an incredible year. We at Amazon.com are grateful to our customers for their business and\", 0.2868215695064787], ['in online bookselling. By many measures, Amazon.com came a long way in 1997: Sales grew from $15.7 million in 1996 to $147.8 million - an 838% increase. Cumulative customer accounts grew from 180,000 to 1,510,000 - a 738% increase. The percentage of orders from repeat customers grew from over 46% in the fourth quarter of 1996 to', 0.27766162391485383]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_similarities = sorted(similarites, key=lambda x: x[1], reverse=True)\n",
    "print(top_similarities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = f\"\"\"\n",
    "<context>\n",
    "{top_similarities[:5]}\n",
    "</context>\n",
    "\n",
    "<instruction>\n",
    "Based on the context above, annswer the questions asked. Only use the information in the context. if the information is not there, answer with: I dont know.\n",
    "</instruction>\n",
    "\n",
    "<text>\n",
    "{question}\n",
    "</text>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "\n",
    "request_body = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"temperature\": 0,\n",
    "    'top_p': 0.002,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt_text}]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=json.dumps(request_body)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I don't know what specifically happened in October at Amazon. The context mentions that a second distribution center was launched in Delaware in November, but there is no mention of any events in October.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response['body'].read())\n",
    "generated_text = response_body['content'][0]['text']\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
